{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "\n",
    "\n",
    "## 2. Methodology\n",
    "\n",
    "\n",
    "## 3. Web Scraping\n",
    "\n",
    "### 3.1 Scraping an article\n",
    "\n",
    "\n",
    "### [3.2 Scraping all article links](#3.2.-Scraping-all-article-links)\n",
    "\n",
    "\n",
    "### [3.3 Putting it all together](#3.3.-Putting-it-all-together)\n",
    "\n",
    "\n",
    "## 4. Text Analysis\n",
    "### 4.1 Exploratory Data Analysis\n",
    "### 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back in April 2019 an extradition bill that would have allowed for criminal suspects to be extradited to mainland China under certain circumstances was introduced in Hong Kong. \n",
    "Many have said this risked exposing Hong-Kongers to unfair trials and violent treament. They also fear that the bill would give China greater influence over Hong Kong and could pose a threat to their freedom of speech.\n",
    "\n",
    "The first protest took place on the 28th April, with tens of thousands of people marching peacefully against the extradition bill. Throughout May lawmakers attempted to come to an agreement over the bill but failed to do so on several occastions.\n",
    "\n",
    "9th June 2019 - More than one million people took to the street to protest peacefully against the bill, however the protest turned ugly after midnight as violent protesters clash with riot police. This would mark the beginning of one of the most violent 6 months period in Hong Kong's recent history, with radical protesters clashing with police for over 50 consectutive weekends. \n",
    "\n",
    "After having witnessed the events myself and been exposed to several media outlets, I saw that frequently newspaper and online articles were simply not reporting the truth whether it was due to lack of accurate facts or simply being bias to one side. I decided to look into this matter further.\n",
    "\n",
    "The ultimate aim of this project is to analysis the news articles covering the Hong Kong protest and try to determine whether an outlet is pro-democracy, pro-Beijing or neutral. Machine learning will be utilised, more specifically Neural Language Processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Scraping an article\n",
    "\n",
    "Before I even begin to scape anything from the article I need to find the relevant HTML tags and content boxes for the data that I am collecting from that article. This included the article header,  summary,  timestamp,  author and the main body text. As this will be a text based analysis I did not include the article images. First let's begin by installing the modules that I will need to scrape the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-be5d928235a1>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-be5d928235a1>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    except Exception as e:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "link = 'https://www.scmp.com/print/news/hong-kong/politics/article/3014737/nearly-2-million-people-take-streets-forcing-public-apology'\n",
    "source = requests.get(link).text\n",
    "soup = BeautifulSoup(source, 'html5lib')\n",
    "print(soup.prettify())\n",
    "\n",
    "for article in soup.find_all('div', class_='article__wrapper wrapper'):\n",
    "    title = article.h1.text\n",
    "    print(f'Title: {title}')\n",
    "\n",
    "    for summaries in article.find_all('li', class_='print-article__summary--li content--li'):\n",
    "        summary = summaries.getText()\n",
    "        print(f'Summary >>>> {summary}')\n",
    "        \n",
    "    date_published = article.find('p', class_='last-update__published published')\n",
    "    date = date_published.time.getText()\n",
    "    print(f'Date Published >>>> {date[10:]}')\n",
    "\n",
    "    for main_text in article.find_all('div', class_='print-article__body article-details-type--p content--p'):\n",
    "        main_text_title = main_text.getText()\n",
    "        print(f'Main Text Title >>>> {main_text_title}')\n",
    "\n",
    "    for main_text2 in article.find_all('p', class_='print-article__body article-details-type--p content--p'):\n",
    "        paragraphs = main_text2.getText()\n",
    "        print(f'Article Text >>>> {paragraphs}')\n",
    "    \n",
    "    for item in article:\n",
    "        # unix timestamp included the millisecond so divide by 1000 is required\n",
    "        writer.writerow({'title': title, 'summary': summary,'date': date, 'main_text_title': main_text_title, 'paragraphs': paragraphs})\n",
    "        \n",
    "    except Exception as e:\n",
    "            writer.writerow({'title': '', 'summary': '', 'date': '', 'main_text_title': '', 'paragraphs': ''})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Scraping all article links\n",
    "\n",
    "I have decided to start with scraping all the article linkes from South China Morning Post as I found them to be fairly netural and tend to cover most of the facts when available. The link I am using is https://www.scmp.com/topics/hong-kong-protests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Putting it all together\n",
    "\n",
    "I now need to use the function written in 3.1 to read the CSV containing all the URLs and scrape all the information from each individual article.\n",
    "The CSV file contains rows where there is an apostrophe, which is causing an issue when reading. To resolve this the delimiter \"'\" will need to be doubled for the CSV to read correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
